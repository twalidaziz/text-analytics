{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b523e444-829f-497a-b9df-766d2a6bc7cb",
   "metadata": {},
   "source": [
    "### Tariq Walid Bin Abd Aziz (SW01083016)\n",
    "### Montasir Kamal Eldin Mohamed (IS01080844)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f9f651-8a31-4c09-9842-a4c1985fb2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31b892dc-298b-4c45-8c82-3ee5fa4c38cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get nrows of data from CSV file\n",
    "df = pd.read_csv(\"Reviews.csv\", nrows=70000, encoding=\"ISO-8859-1\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dc0781-81ea-4037-88a4-fc908d279088",
   "metadata": {},
   "source": [
    "# 1. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a9fd0c5-c778-494e-9b68-9be441cdeeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get english stop words\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Define custom stop words\n",
    "more_stopwords = ['u', 'im', 'c']\n",
    "stop_words = stop_words + more_stopwords\n",
    "\n",
    "# Stemmer and lemmatizer\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29d8e456-51c6-4120-8d86-17acf218845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and standardize\n",
    "def preprocess(text):\n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove text within square brackets\n",
    "    text = re.sub(r'http\\S+\\s*\\S+', '', text)  # Remove URLs starting with http\n",
    "    text = re.sub(r'www\\.\\S+', '', text)  # Remove URLs starting with www\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\b\\w*\\d\\w*\\b', '', text)  # Remove words containing numbers\n",
    "    text = ' '.join(word for word in text.split(' ') if word not in stop_words) # Remove stopwords\n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split(' ')) # Stemming\n",
    "    text = ' '.join(lemmatizer.lemmatize(word) for word in text.split(' ')) # Lemmatizing   \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4833b164-91cb-40e9-a56b-f746aafcf23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>positive</td>\n",
       "      <td>bought sever vital can dog food product found ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>negative</td>\n",
       "      <td>product arriv label jumbo salt peanutsth peanu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>positive</td>\n",
       "      <td>confect around centuri  light pillowi citrus g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>look secret ingredi robitussin believ found  g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>positive</td>\n",
       "      <td>great taffi great price  wide assort yummi taf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "      label                                         text_clean  \n",
       "0  positive  bought sever vital can dog food product found ...  \n",
       "1  negative  product arriv label jumbo salt peanutsth peanu...  \n",
       "2  positive  confect around centuri  light pillowi citrus g...  \n",
       "3  negative  look secret ingredi robitussin believ found  g...  \n",
       "4  positive  great taffi great price  wide assort yummi taf...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map 'Score' in dataset to 'label' column (positive, negative, neutral)\n",
    "df['label'] = df.Score.map({1:'negative', 2:'negative', 3:'neutral', 4:'positive', 5:'positive'})\n",
    "\n",
    "# Apply text preprocessing to dataset\n",
    "df['text_clean'] = df['Text'].apply(preprocess)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05f1136-339a-4441-8836-6cc702f197dd",
   "metadata": {},
   "source": [
    "# 2. Feature Extraction\n",
    "## Bag-of-Words for ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f3fe91a-a8da-419a-8fcd-599f75630531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "texts = df['text_clean']\n",
    "labels = df['label']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "# Extract features (bag-of-words representation)\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a84cfa-5a33-4d08-a178-d485b6490af2",
   "metadata": {},
   "source": [
    "# 3. Model Selection & Evaluation\n",
    "## Lexicon-based Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e072a9f-1b46-45df-98c3-675de02118bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEXICON-BASED APPROACH:\n",
      "\n",
      "TextBlob Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.26      0.31     10537\n",
      "     neutral       0.06      0.04      0.04      5538\n",
      "    positive       0.81      0.90      0.85     53925\n",
      "\n",
      "    accuracy                           0.73     70000\n",
      "   macro avg       0.42      0.40      0.40     70000\n",
      "weighted avg       0.69      0.73      0.71     70000\n",
      "\n",
      "\n",
      "VADER Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.49      0.26      0.34     10537\n",
      "     neutral       0.10      0.05      0.06      5538\n",
      "    positive       0.81      0.93      0.87     53925\n",
      "\n",
      "    accuracy                           0.76     70000\n",
      "   macro avg       0.47      0.41      0.42     70000\n",
      "weighted avg       0.71      0.76      0.72     70000\n",
      "\n",
      "\n",
      "Execution Time: 489.63700795173645 seconds\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import classification_report\n",
    "from tabulate import tabulate\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# Function to perform sentiment analysis on a single review\n",
    "def analyze_sentiment(review):\n",
    "    # TextBlob\n",
    "    blob = TextBlob(review)\n",
    "    tb_polarity = blob.sentiment.polarity\n",
    "    if tb_polarity > 0:\n",
    "        tb_label = 'positive'\n",
    "    elif tb_polarity < 0:\n",
    "        tb_label = 'negative'\n",
    "    else:\n",
    "        tb_label = 'neutral'\n",
    "    \n",
    "    # VADER\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    vs = analyzer.polarity_scores(review)\n",
    "    vader_compound = vs['compound']\n",
    "    if vader_compound > 0.05:\n",
    "        vader_label = 'positive'\n",
    "    elif vader_compound < -0.05:\n",
    "        vader_label = 'negative'\n",
    "    else:\n",
    "        vader_label = 'neutral'\n",
    "    \n",
    "    return tb_label, vader_label\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    reviews = df['text_clean']\n",
    "    actual_labels = df['label']\n",
    "\n",
    "    print(\"LEXICON-BASED APPROACH:\")\n",
    "\n",
    "    # Get start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Initialize multiprocessing pool\n",
    "    pool = multiprocessing.Pool()\n",
    "    \n",
    "    # Perform sentiment analysis using multiprocessing\n",
    "    results = pool.map(analyze_sentiment, reviews)\n",
    "    \n",
    "    # Close the pool to release resources\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    # Record end time\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Unpack the results\n",
    "    tb_labels, vader_labels = zip(*results)\n",
    "    \n",
    "    # Calculate classification report for TextBlob\n",
    "    tb_report = classification_report(actual_labels, tb_labels)\n",
    "    \n",
    "    # Calculate classification report for VADER\n",
    "    vader_report = classification_report(actual_labels, vader_labels)\n",
    "    \n",
    "    # Print classification report for TextBlob\n",
    "    print(\"\\nTextBlob Classification Report:\")\n",
    "    print(tb_report)\n",
    "    \n",
    "    # Print classification report for VADER\n",
    "    print(\"\\nVADER Classification Report:\")\n",
    "    print(vader_report)\n",
    "\n",
    "    # Calculate and print execution time\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"\\nExecution Time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70867198-5269-4b1b-b8e8-9850ad514580",
   "metadata": {},
   "source": [
    "## Machine-Learning-Based Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c35088f-32ed-47d0-9f22-39a0ca0db321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import multiprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ded7a39f-ed7a-495e-9175-40488edf2f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING COMPLETED\n",
      "\n",
      "Execution Time: 2547.965203523636 seconds\n"
     ]
    }
   ],
   "source": [
    "# Funtion for training classifier\n",
    "def train_classifier(classifier, X_train, y_train):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return classifier\n",
    "\n",
    "# Initialize classifiers\n",
    "nb_classifier = MultinomialNB()\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize multiprocessing pool\n",
    "pool = multiprocessing.Pool()\n",
    "\n",
    "# Train classifiers using multiprocessing pool\n",
    "nb_classifier = pool.apply(train_classifier, args=(nb_classifier, X_train, y_train))\n",
    "svm_classifier = pool.apply(train_classifier, args=(svm_classifier, X_train, y_train))\n",
    "\n",
    "# Close multiprocessing pool\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"TRAINING COMPLETED\")\n",
    "# Calculate and print execution time\n",
    "execution_time = end_time - start_time\n",
    "print(f\"\\nExecution Time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "919d1b13-c592-46de-a6e3-898f5c2e27c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACHINE-LEARNING-BASED APPROACH:\n",
      "\n",
      "Classification Report for Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.48      0.58      4231\n",
      "     neutral       0.44      0.06      0.10      2221\n",
      "    positive       0.84      0.98      0.90     21548\n",
      "\n",
      "    accuracy                           0.83     28000\n",
      "   macro avg       0.67      0.50      0.53     28000\n",
      "weighted avg       0.79      0.83      0.79     28000\n",
      "\n",
      "\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.66      0.65      4231\n",
      "     neutral       0.36      0.27      0.31      2221\n",
      "    positive       0.90      0.92      0.91     21548\n",
      "\n",
      "    accuracy                           0.83     28000\n",
      "   macro avg       0.64      0.62      0.62     28000\n",
      "weighted avg       0.82      0.83      0.83     28000\n",
      "\n",
      "\n",
      "Execution Time: 308.5540678501129 seconds\n"
     ]
    }
   ],
   "source": [
    "# Machine-learning-based approach using Naive Bayes and SVM\n",
    "print(\"MACHINE-LEARNING-BASED APPROACH:\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Predict sentiment using classifiers\n",
    "for text, actual_label in zip(X_test, y_test):\n",
    "    # Predict sentiment using Naive Bayes\n",
    "    nb_prediction = nb_classifier.predict(text)[0]\n",
    "\n",
    "    # Predict sentiment using SVM\n",
    "    svm_prediction = svm_classifier.predict(text)[0]\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate classification report for Naive Bayes\n",
    "nb_classification_report = classification_report(y_test, nb_classifier.predict(X_test), target_names=['negative', 'neutral', 'positive'])\n",
    "\n",
    "# Calculate classification report for SVM\n",
    "svm_classification_report = classification_report(y_test, svm_classifier.predict(X_test), target_names=['negative', 'neutral', 'positive'])\n",
    "\n",
    "# Print classification report for Naive Bayes\n",
    "print(\"\\nClassification Report for Naive Bayes:\")\n",
    "print(nb_classification_report)\n",
    "\n",
    "# Print classification report for SVM\n",
    "print(\"\\nClassification Report for SVM:\")\n",
    "print(svm_classification_report)\n",
    "\n",
    "# Calculate and print execution time\n",
    "execution_time = end_time - start_time\n",
    "print(f\"\\nExecution Time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ca2f6a-50a5-49f7-94ed-18eb64e997d9",
   "metadata": {},
   "source": [
    "# 4. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffdf6e1-e512-474d-8d39-52026d531009",
   "metadata": {},
   "source": [
    "#### Both lexicon-based and ML approaches perform well in classifying positive sentiments. However, ML methods (using Naive Bayes and SVM classifiers) perform slightly better over lexicon-based models in positive sentiment classification.\n",
    "\n",
    "#### Both lexicon-based and ML approaches struggle poorly in accurately classifying neutral reviews, with lexicon methods almost always misclassifying them. Eventhough Naive Bayes and SVM classifiers outperform TextBlob and VADER analyzers, they still show weaknees in predicting neutral sentiments.\n",
    "\n",
    "#### Both ML classification methods show decent performance in classifying negative reviews, with Naive Bayes demonstrating a slight edge over the SVM classifier. On the contrary, TextBlob and SVM analyzers show poor performance in classifying negative reviews.\n",
    "\n",
    "#### In terms of accuracy, ML classification methods outperform lexicon-based analyzers by a margin of 7%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd29b6b-bb25-40e9-a8ea-b29757e5ff20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
